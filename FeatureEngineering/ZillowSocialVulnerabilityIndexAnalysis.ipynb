{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f093b8-91af-448c-958d-3e157a9cb6eb",
   "metadata": {},
   "source": [
    "# Utilize data from Zillow and combine that with Social Vulnerability (SVI) index\n",
    "Data available through CDC to demonstrate relationship between social\n",
    "vulnerability and their impact on, home sale prices, days between on-market to\n",
    "pending, price increases etc.\n",
    "\n",
    " - Zillow data is available at: https://www.zillow.com/research/data/\n",
    " - SVI data is available at:\n",
    "https://www.atsdr.cdc.gov/placeandhealth/svi/data_documentation_download.html\n",
    " - In this example, data sets may use different geo-identifiers so you may have to\n",
    "cross walk tables provided by HUD or come up with your own mechanism to\n",
    "harmonize the different geographical divisions.\n",
    "(https://www.huduser.gov/portal/datasets/usps_crosswalk.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e943cf8",
   "metadata": {},
   "source": [
    "# Plan to Obtain Zillow Days on Market Data and HUD's Vulnerability Index\n",
    "\n",
    "## Step 1: Create geocoding tables\n",
    "1. **Secure Gazzeteer files**\n",
    "    - Since Zillow uses MSA and Zipcodes for publishing their data and CDC uses FIPS code (county level), it is critical that we have a geospatial baseline to correlate the two\n",
    "2. **Latitude and Longitude**\n",
    "    - While there are files that provide county FIPS codes (as GeoIDs), the grains are NOT consistent across these two datasets we will adopt Lat and Lon codes for every MSA and CDC counties to tether the two data layers\n",
    "3. **S2 Codes**\n",
    "    - The latitude and longitudes of the two datasets, being floating point numbers, leave plenty of theta join conditions to marry the two. Its non-performant and prone to gaps. We will therefore use s2sphere (\"locality preserving\" space filling curve index which has similar 1D indices for geolocations that are closer to each other on 2D earth) to quickly locate fuzzy proximate matching between two layer coordinates\n",
    "    - We will stamp in s2codes and marry the two Zillow zipcodes and CDC FIPS codes using lat/lon. We will merge these using `pandas.merge_asof` operation.\n",
    "\n",
    "## Step 2: Obtain Zillow Days on Market Data\n",
    "1. **Identify Data Source**: \n",
    "    - Zillow provides various datasets, including Days on Market (DoM) data.\n",
    "    - The data can be accessed from Zillow's research data page: [Zillow Research Data](https://www.zillow.com/research/data/).\n",
    "\n",
    "2. **Download Data**:\n",
    "    - Download the DoM data from Zillow's website.\n",
    "    - Ensure the data is in a suitable format (e.g., CSV).\n",
    "\n",
    "3. **Load Data into Jupyter Notebook**:\n",
    "    - Use `pandas` to read the CSV file into a DataFrame.\n",
    "    - Perform initial data cleaning and preprocessing if necessary.\n",
    "\n",
    "4. **Save Data Locally**:\n",
    "    - Save the cleaned data to a local file for future use.\n",
    "\n",
    "## Step 3: Obtain HUD's Vulnerability Index\n",
    "1. **Identify Data Source**:\n",
    "    - The Social Vulnerability Index (SVI) data is available through the CDC.\n",
    "    - The data can be accessed from the CDC's SVI page: [CDC SVI Data](https://www.atsdr.cdc.gov/placeandhealth/svi/data_documentation_download.html).\n",
    "\n",
    "2. **Download Data**:\n",
    "    - Download the SVI data from the CDC's website.\n",
    "    - Ensure the data is in a suitable format (e.g., CSV).\n",
    "\n",
    "3. **Load Data into Jupyter Notebook**:\n",
    "    - Use `pandas` to read the CSV file into a DataFrame.\n",
    "    - Perform initial data cleaning and preprocessing if necessary.\n",
    "\n",
    "4. **Save Data Locally**:\n",
    "    - Save the cleaned data to a local file for future use.\n",
    "\n",
    "## Step 3: Data Harmonization\n",
    "1. **Geographical Crosswalk**:\n",
    "    - Use geographical crosswalk tables (reference tables built in first step) provided by HUD to harmonize different geographical divisions.\n",
    "    - Ensure that the Zillow and SVI data can be joined on common s2spehere cell IDs using \"fuzzy\" `pd.merge_asof` logic.\n",
    "\n",
    "2. **Data Integration**:\n",
    "    - Integrate the Zillow DoM data with the SVI data.\n",
    "    - Ensure that the integrated dataset is clean and ready for analysis.\n",
    "    - Persist this data for analysis in a separate notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c6440a-f02a-4d54-8055-07b8479f3963",
   "metadata": {},
   "source": [
    "# Spark Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca00651d-0070-4cb0-9be5-5aa8d7fd1318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/08 09:41:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import atexit\n",
    "import io\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "if \"spark\" not in vars():\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "    import pyspark.sql.functions as F\n",
    "    import pyspark.sql.types as T\n",
    "    from pyspark.sql import DataFrame, SparkSession\n",
    "    from pyspark.sql.types import (\n",
    "        FloatType,\n",
    "        IntegerType,\n",
    "        StringType,\n",
    "        StructField,\n",
    "        StructType,\n",
    "    )\n",
    "    from pyspark.sql.window import Window\n",
    "    from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "    spark = (\n",
    "        SparkSession.builder.master(\"local[8,2]\")\n",
    "        .config(\"spark.driver.memory\", \"1g\")\n",
    "        .enableHiveSupport()\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    atexit.register(lambda: spark.stop())\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import DataFrame, Row, SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "def cleanse_val(val):\n",
    "    return re.sub(r\"([^\\s\\w\\d])+\", \"\", val.lower()).strip() if val else \"\"\n",
    "\n",
    "\n",
    "def reg(spark_df, name=None):\n",
    "    uniqsig = \"df_{0}\".format(cleanse_val(str(uuid.uuid4()))) if not name else name\n",
    "    spark_df.createOrReplaceTempView(uniqsig)\n",
    "    return uniqsig\n",
    "\n",
    "\n",
    "def show(df, rows=5):\n",
    "    display(df.limit(rows).toPandas())\n",
    "\n",
    "\n",
    "# Override table show/registration functions\n",
    "DataFrame.reg = reg\n",
    "DataFrame.dshow = show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f9fcd7-843a-438e-9ff3-c3b0dd767f87",
   "metadata": {},
   "source": [
    "## Step 1. Geocoding Data from Census Gezzetter files\n",
    "\n",
    "This is the source that first maps county level FIPS to lat/lon info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b232706-9fc6-478c-9ee7-b9018c3beeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pyspark/sql/pandas/conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>GeoID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>02100</td>\n",
       "      <td>59.098404</td>\n",
       "      <td>-135.575791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>06059</td>\n",
       "      <td>33.730653</td>\n",
       "      <td>-117.860925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GA</td>\n",
       "      <td>13095</td>\n",
       "      <td>31.564073</td>\n",
       "      <td>-84.163457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID</td>\n",
       "      <td>16017</td>\n",
       "      <td>48.263410</td>\n",
       "      <td>-116.622180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IL</td>\n",
       "      <td>17125</td>\n",
       "      <td>40.259177</td>\n",
       "      <td>-89.900969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  GeoID   Latitude   Longitude\n",
       "0    AK  02100  59.098404 -135.575791\n",
       "1    CA  06059  33.730653 -117.860925\n",
       "2    GA  13095  31.564073  -84.163457\n",
       "3    ID  16017  48.263410 -116.622180\n",
       "4    IL  17125  40.259177  -89.900969"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zip_county_geocode = (\n",
    "    pd.read_csv(\n",
    "        \"data/2024_Gaz_tracts_national.txt\",\n",
    "        sep=r\"\\s+\",\n",
    "        usecols=[\"USPS\", \"GEOID\", \"INTPTLAT\", \"INTPTLONG\"],\n",
    "        dtype=str,\n",
    "    )\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    ")\n",
    "zip_county_geocode_df = spark.createDataFrame(zip_county_geocode).cache()\n",
    "zip_county_geocode_df = (\n",
    "    zip_county_geocode_df.groupBy(\n",
    "        F.col(\"USPS\").alias(\"State\"),\n",
    "        F.expr('substr(lpad(GEOID, 11, \"0\"), 0, 5)').alias(\"GeoID\"),\n",
    "    )\n",
    "    .agg(F.mean(\"INTPTLAT\").alias(\"Latitude\"), F.mean(\"INTPTLONG\").alias(\"Longitude\"))\n",
    "    .cache()\n",
    ")\n",
    "zip_county_geocode_df.dshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb29fb3",
   "metadata": {},
   "source": [
    "## S2 Cell Mapping Logic\n",
    "\n",
    "The S2 geometry library is used to map latitude and longitude coordinates to S2 cells. S2 cells are hierarchical, equal-area cells that cover the surface of a sphere. This allows for efficient spatial indexing and querying.\n",
    "\n",
    "### Function Description\n",
    "\n",
    "The function `latlon_to_s2id` is a pyspark UDF that takes latitude and longitude coordinates and maps them to S2 cell ID. A 20-character long number. LongLongType in `C++`. To shim it in Python, we will use `string` serde format.\n",
    "\n",
    "### Steps\n",
    "1. **Latitude and Longitude Validation**:\n",
    "    - The function first checks if the latitude and longitude are valid floating-point numbers within their respective ranges (-90 to 90 for latitude and -180 to 180 for longitude).\n",
    "\n",
    "2. **Conversion to S2 Cell ID**:\n",
    "    - If the coordinates are valid, they are converted to an S2 cell ID using the `s2sphere` library. This involves creating an `LatLng` object from the latitude and longitude, and then converting it to an S2 cell ID.\n",
    "\n",
    "3. **Return S2 Cell ID**:\n",
    "    - The function returns the S2 cell ID. If the input coordinates are invalid, it returns `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcd46f0",
   "metadata": {},
   "source": [
    "## Step 2. Geocoding Data from HUD crosswalk files\n",
    "\n",
    "This is the source that first city level zip to lat/lon info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f55c48f-97d1-46f5-9f8c-12b5e85ee2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pyspark/sql/pandas/conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeoID</th>\n",
       "      <th>CountyFIPS</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>S2Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2501730700</td>\n",
       "      <td>25017</td>\n",
       "      <td>02053</td>\n",
       "      <td>MEDWAY</td>\n",
       "      <td>MA</td>\n",
       "      <td>42.442690</td>\n",
       "      <td>-71.246332</td>\n",
       "      <td>09935956960593095687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2502182315</td>\n",
       "      <td>25021</td>\n",
       "      <td>02070</td>\n",
       "      <td>SHELDONVILLE</td>\n",
       "      <td>MA</td>\n",
       "      <td>42.204774</td>\n",
       "      <td>-71.143206</td>\n",
       "      <td>09936209396979585163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2502116495</td>\n",
       "      <td>25021</td>\n",
       "      <td>02090</td>\n",
       "      <td>WESTWOOD</td>\n",
       "      <td>MA</td>\n",
       "      <td>42.204774</td>\n",
       "      <td>-71.143206</td>\n",
       "      <td>09936209396979585163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3301104900</td>\n",
       "      <td>33011</td>\n",
       "      <td>03442</td>\n",
       "      <td>BENNINGTON</td>\n",
       "      <td>NH</td>\n",
       "      <td>42.881262</td>\n",
       "      <td>-71.548593</td>\n",
       "      <td>09935984454483744731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2303137270</td>\n",
       "      <td>23031</td>\n",
       "      <td>03904</td>\n",
       "      <td>KITTERY</td>\n",
       "      <td>ME</td>\n",
       "      <td>43.427069</td>\n",
       "      <td>-70.622500</td>\n",
       "      <td>05526674384555133445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GeoID CountyFIPS    ZIP          City State   Latitude  Longitude  \\\n",
       "0  2501730700      25017  02053        MEDWAY    MA  42.442690 -71.246332   \n",
       "1  2502182315      25021  02070  SHELDONVILLE    MA  42.204774 -71.143206   \n",
       "2  2502116495      25021  02090      WESTWOOD    MA  42.204774 -71.143206   \n",
       "3  3301104900      33011  03442    BENNINGTON    NH  42.881262 -71.548593   \n",
       "4  2303137270      23031  03904       KITTERY    ME  43.427069 -70.622500   \n",
       "\n",
       "                   S2Id  \n",
       "0  09935956960593095687  \n",
       "1  09936209396979585163  \n",
       "2  09936209396979585163  \n",
       "3  09935984454483744731  \n",
       "4  05526674384555133445  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data is at https://www.huduser.gov/apps/public/uspscrosswalk/home\n",
    "county_zip_df = spark.createDataFrame(\n",
    "    pd.read_excel(\n",
    "        \"data/COUNTY_SUB_ZIP_062024.xlsx\",\n",
    "        usecols=[\"COUNTY_SUB\", \"ZIP\", \"USPS_ZIP_PREF_CITY\", \"USPS_ZIP_PREF_STATE\"],\n",
    "        dtype=str,\n",
    "    )\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    ")\n",
    "county_zip_df = county_zip_df.select(\n",
    "    F.expr('lpad(COUNTY_SUB, 10, \"0\")').alias(\"GeoID\"),\n",
    "    F.expr('substr(lpad(COUNTY_SUB, 10, \"0\"), 0, 5)').alias(\"CountyFIPS\"),\n",
    "    F.col(\"ZIP\"),\n",
    "    F.col(\"USPS_ZIP_PREF_CITY\").alias(\"City\"),\n",
    "    F.col(\"USPS_ZIP_PREF_STATE\").alias(\"State\"),\n",
    ")\n",
    "\n",
    "from s2sphere import CellId, LatLng\n",
    "\n",
    "\n",
    "# Function to convert latitude and longitude to S2 cell ID\n",
    "def latlon_to_s2id(lat, lon):\n",
    "    # Check if lat and lon are floats and within valid ranges\n",
    "    if isinstance(lat, (int, float)) and isinstance(lon, (int, float)):\n",
    "        if -90 <= lat <= 90 and -180 <= lon <= 180:\n",
    "            latlng = LatLng.from_degrees(lat, lon)\n",
    "            cell = CellId.from_lat_lng(latlng)\n",
    "            return cell.id()\n",
    "    # Return None if the inputs are invalid\n",
    "    return None\n",
    "\n",
    "\n",
    "# Map S2 Code for Geo geometry\n",
    "geocodes_df = (\n",
    "    spark.sql(\n",
    "        f\"\"\"select a.*, b.Latitude, b.Longitude from {county_zip_df.reg()} a\n",
    "    left join {zip_county_geocode_df.reg()} b\n",
    "    on a.CountyFIPS=b.GeoID and a.State=b.State\"\"\"\n",
    "    )\n",
    "    .drop_duplicates([\"ZIP\"])\n",
    "    .withColumn(\n",
    "        \"S2Id\",\n",
    "        F.lpad(F.udf(latlon_to_s2id, T.StringType())(\"Latitude\", \"Longitude\"), 20, \"0\"),\n",
    "    )\n",
    ").cache()\n",
    "\n",
    "geocodes_df.dshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becaf026-e403-4f65-8e07-f6e29f2b013e",
   "metadata": {},
   "source": [
    "## Read GeoID to Zipcode Mapping\n",
    "\n",
    "The data from Zillow is by GeoID (for metrics) and Zipcode (as primary key). Its unfortunate that they have two level referential mapping: Zillow maps housing metrics to MSA in one file. In a separate file, without a consistent MSA *\"ID\"*, they list zipcodes and normalized string attributes for MSA in another file. So we have to download both referential files and map the geocodes for their metrics.\n",
    "\n",
    " - 1. First file gather metrics (in real numbers) by MSA city, state, county (in string form)\n",
    " - 2. Second, we gather the zip code to MSA string attributes\n",
    " - 3. Third, we crosswalk MSA metrics to zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbce2486-097f-4e09-b06d-865ab0081e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>91982</td>\n",
       "      <td>1</td>\n",
       "      <td>77494</td>\n",
       "      <td>zip</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>KATY</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>Fort Bend County</td>\n",
       "      <td>FORT BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61148</td>\n",
       "      <td>2</td>\n",
       "      <td>08701</td>\n",
       "      <td>zip</td>\n",
       "      <td>NJ</td>\n",
       "      <td>NJ</td>\n",
       "      <td>LAKEWOOD</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>Ocean County</td>\n",
       "      <td>OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>91940</td>\n",
       "      <td>3</td>\n",
       "      <td>77449</td>\n",
       "      <td>zip</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>KATY</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>Harris County</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62080</td>\n",
       "      <td>4</td>\n",
       "      <td>11368</td>\n",
       "      <td>zip</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>Queens County</td>\n",
       "      <td>QUEENS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>91733</td>\n",
       "      <td>5</td>\n",
       "      <td>77084</td>\n",
       "      <td>zip</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>Harris County</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index RegionID SizeRank RegionName RegionType StateName State      City  \\\n",
       "0      0    91982        1      77494        zip        TX    TX      KATY   \n",
       "1      1    61148        2      08701        zip        NJ    NJ  LAKEWOOD   \n",
       "2      2    91940        3      77449        zip        TX    TX      KATY   \n",
       "3      3    62080        4      11368        zip        NY    NY  NEW YORK   \n",
       "4      4    91733        5      77084        zip        TX    TX   HOUSTON   \n",
       "\n",
       "                                   Metro        CountyName     County  \n",
       "0   Houston-The Woodlands-Sugar Land, TX  Fort Bend County  FORT BEND  \n",
       "1  New York-Newark-Jersey City, NY-NJ-PA      Ocean County      OCEAN  \n",
       "2   Houston-The Woodlands-Sugar Land, TX     Harris County     HARRIS  \n",
       "3  New York-Newark-Jersey City, NY-NJ-PA     Queens County     QUEENS  \n",
       "4   Houston-The Woodlands-Sugar Land, TX     Harris County     HARRIS  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "zillow_metro_map_file = \"data/zillow_metro_ref_map.csv\"\n",
    "zillow_metro_missing_map_file = \"data/Missing_Zips.csv\"\n",
    "zillow_metro_map_file_exists = os.path.exists(\n",
    "    zillow_metro_map_file\n",
    ")  # Does the mapping file aready exist?\n",
    "\n",
    "# Read from Internet if mapping from Metro to Geo data is NOT already present\n",
    "zillow_home_values_zip_ref = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.read_csv(\n",
    "                \"https://files.zillowstatic.com/research/public_csvs/zhvf_growth/Zip_zhvf_growth_uc_sfrcondo_tier_0.33_0.67_month.csv?t=1730940305\",\n",
    "                usecols=[\n",
    "                    \"RegionID\",\n",
    "                    \"SizeRank\",\n",
    "                    \"RegionName\",\n",
    "                    \"RegionType\",\n",
    "                    \"StateName\",\n",
    "                    \"State\",\n",
    "                    \"City\",\n",
    "                    \"Metro\",\n",
    "                    \"CountyName\",\n",
    "                ],\n",
    "                dtype=str,\n",
    "            )\n",
    "            .fillna(\"\")\n",
    "            .astype(str),\n",
    "            pd.read_csv(zillow_metro_missing_map_file, dtype=str)\n",
    "            .fillna(\"\")\n",
    "            .astype(str),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    ).reset_index()\n",
    "    if not zillow_metro_map_file_exists\n",
    "    else pd.read_csv(zillow_metro_map_file, dtype=str).fillna(\"\").astype(str)\n",
    ")\n",
    "\n",
    "if not zillow_metro_map_file_exists:\n",
    "    zillow_home_values_zip_ref[\"City\"] = zillow_home_values_zip_ref[\"City\"].apply(\n",
    "        lambda x: x.strip().upper() if x else \"\"\n",
    "    )\n",
    "    zillow_home_values_zip_ref[\"County\"] = (\n",
    "        zillow_home_values_zip_ref[\"CountyName\"]\n",
    "        .str.replace(r\" COUNTY$\", \"\", case=False, regex=True)\n",
    "        .apply(lambda x: x.strip().upper())\n",
    "    )\n",
    "\n",
    "    zillow_home_values_zip_ref.to_csv(\n",
    "        zillow_metro_map_file,\n",
    "        index=False,\n",
    "    )  # Save for later\n",
    "    zillow_metro_map_file_exists = os.path.exists(zillow_metro_map_file)\n",
    "\n",
    "display(zillow_home_values_zip_ref.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb4d582-a8d0-4e53-bf5a-e6dddfbef935",
   "metadata": {},
   "source": [
    "## Zillow Step 2. Days on Market values\n",
    "Get data from Zillow for DoM and persist locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4923b33c-4711-434a-a7bc-ac7f474590fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>2024-10-05</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394913</td>\n",
       "      <td>1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>msa</td>\n",
       "      <td>NY</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>753899</td>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>msa</td>\n",
       "      <td>CA</td>\n",
       "      <td>39.0</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394463</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>msa</td>\n",
       "      <td>IL</td>\n",
       "      <td>32.0</td>\n",
       "      <td>CHICAGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394514</td>\n",
       "      <td>4</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>55.0</td>\n",
       "      <td>DALLAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>394692</td>\n",
       "      <td>5</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>61.0</td>\n",
       "      <td>HOUSTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>394472</td>\n",
       "      <td>492</td>\n",
       "      <td>Clearlake, CA</td>\n",
       "      <td>msa</td>\n",
       "      <td>CA</td>\n",
       "      <td>86.0</td>\n",
       "      <td>CLEARLAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>394759</td>\n",
       "      <td>519</td>\n",
       "      <td>Laconia, NH</td>\n",
       "      <td>msa</td>\n",
       "      <td>NH</td>\n",
       "      <td>39.0</td>\n",
       "      <td>LACONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>845162</td>\n",
       "      <td>535</td>\n",
       "      <td>Granbury, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>72.0</td>\n",
       "      <td>GRANBURY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>753905</td>\n",
       "      <td>604</td>\n",
       "      <td>Newport, OR</td>\n",
       "      <td>msa</td>\n",
       "      <td>OR</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NEWPORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>753871</td>\n",
       "      <td>811</td>\n",
       "      <td>Breckenridge, CO</td>\n",
       "      <td>msa</td>\n",
       "      <td>CO</td>\n",
       "      <td>81.0</td>\n",
       "      <td>BRECKENRIDGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RegionID SizeRank        RegionName RegionType StateName 2024-10-05  \\\n",
       "1     394913        1      New York, NY        msa        NY       58.0   \n",
       "2     753899        2   Los Angeles, CA        msa        CA       39.0   \n",
       "3     394463        3       Chicago, IL        msa        IL       32.0   \n",
       "4     394514        4        Dallas, TX        msa        TX       55.0   \n",
       "5     394692        5       Houston, TX        msa        TX       61.0   \n",
       "..       ...      ...               ...        ...       ...        ...   \n",
       "334   394472      492     Clearlake, CA        msa        CA       86.0   \n",
       "335   394759      519       Laconia, NH        msa        NH       39.0   \n",
       "336   845162      535      Granbury, TX        msa        TX       72.0   \n",
       "337   753905      604       Newport, OR        msa        OR       99.0   \n",
       "338   753871      811  Breckenridge, CO        msa        CO       81.0   \n",
       "\n",
       "             City  \n",
       "1        NEW YORK  \n",
       "2     LOS ANGELES  \n",
       "3         CHICAGO  \n",
       "4          DALLAS  \n",
       "5         HOUSTON  \n",
       "..            ...  \n",
       "334     CLEARLAKE  \n",
       "335       LACONIA  \n",
       "336      GRANBURY  \n",
       "337       NEWPORT  \n",
       "338  BRECKENRIDGE  \n",
       "\n",
       "[338 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2024-10-05'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "zillow_metro_dom_file = \"data/zillow_dom_metro_data.csv\"\n",
    "zillow_metro_dom_file_exists = os.path.exists(\n",
    "    zillow_metro_dom_file\n",
    ")  # Does the days on market file aready exist?\n",
    "\n",
    "# Read from Internet if mapping from Metro to Geo data is NOT already present\n",
    "zillow_dom_data_timeseries = (\n",
    "    pd.read_csv(\n",
    "        \"https://files.zillowstatic.com/research/public_csvs/mean_doz_pending/Metro_mean_doz_pending_uc_sfrcondo_sm_week.csv?t=1730940305\",\n",
    "        dtype=str,\n",
    "    )\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    if not zillow_metro_dom_file_exists\n",
    "    else pd.read_csv(zillow_metro_dom_file, dtype=str).fillna(\"\").astype(str)\n",
    ")\n",
    "\n",
    "latest_date = sorted(\n",
    "    [col for col in zillow_dom_data_timeseries.columns if col[:2] == \"20\"], reverse=True\n",
    ")[0]\n",
    "zillow_dom_data_timeseries = zillow_dom_data_timeseries[\n",
    "    [col for col in zillow_dom_data_timeseries.columns if col[:2] != \"20\"]\n",
    "    + [latest_date]\n",
    "]\n",
    "if not zillow_metro_dom_file_exists:\n",
    "    zillow_dom_data_timeseries = zillow_dom_data_timeseries[\n",
    "        zillow_dom_data_timeseries.RegionType.str.startswith(\"msa\")\n",
    "    ]\n",
    "    zillow_dom_data_timeseries[\"City\"] = zillow_dom_data_timeseries.apply(\n",
    "        lambda x: re.sub(f\", {x.StateName}$\", \"\", str(x.RegionName)).strip(), axis=1\n",
    "    ).apply(lambda x: str(x).strip().upper() if x else \"\")\n",
    "    zillow_dom_data_timeseries.to_csv(\n",
    "        zillow_metro_dom_file,\n",
    "        index=False,\n",
    "    )  # Save for later\n",
    "    zillow_metro_dom_file_exists = os.path.exists(zillow_metro_dom_file)\n",
    "\n",
    "display(zillow_dom_data_timeseries)\n",
    "display(latest_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd6fbf-a2aa-4a59-a46d-a9940d2a1d98",
   "metadata": {},
   "source": [
    "## Zillow Step 3. Map Region IDs to see Zip Info\n",
    "\n",
    "Process in Pyspark just to handle large joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f0ddd1-44c7-4a2c-86cf-65c92273b57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pyspark/sql/pandas/conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>2024-10-05</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>394298</td>\n",
       "      <td>473</td>\n",
       "      <td>Aberdeen, WA</td>\n",
       "      <td>msa</td>\n",
       "      <td>WA</td>\n",
       "      <td>51.0</td>\n",
       "      <td>ABERDEEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394299</td>\n",
       "      <td>251</td>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>60.0</td>\n",
       "      <td>ABILENE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394304</td>\n",
       "      <td>83</td>\n",
       "      <td>Akron, OH</td>\n",
       "      <td>msa</td>\n",
       "      <td>OH</td>\n",
       "      <td>24.0</td>\n",
       "      <td>AKRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394306</td>\n",
       "      <td>295</td>\n",
       "      <td>Albany, GA</td>\n",
       "      <td>msa</td>\n",
       "      <td>GA</td>\n",
       "      <td>65.0</td>\n",
       "      <td>ALBANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394307</td>\n",
       "      <td>330</td>\n",
       "      <td>Albany, OR</td>\n",
       "      <td>msa</td>\n",
       "      <td>OR</td>\n",
       "      <td>39.0</td>\n",
       "      <td>ALBANY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RegionID SizeRank    RegionName RegionType StateName 2024-10-05      City\n",
       "0   394298      473  Aberdeen, WA        msa        WA       51.0  ABERDEEN\n",
       "1   394299      251   Abilene, TX        msa        TX       60.0   ABILENE\n",
       "2   394304       83     Akron, OH        msa        OH       24.0     AKRON\n",
       "3   394306      295    Albany, GA        msa        GA       65.0    ALBANY\n",
       "4   394307      330    Albany, OR        msa        OR       39.0    ALBANY"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30959</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3756</td>\n",
       "      <td>zip</td>\n",
       "      <td>NH</td>\n",
       "      <td>NH</td>\n",
       "      <td>LEBANON</td>\n",
       "      <td>Lebanon-NH</td>\n",
       "      <td>Grafton County</td>\n",
       "      <td>GRAFTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8021</td>\n",
       "      <td>100000</td>\n",
       "      <td>8306</td>\n",
       "      <td>98848</td>\n",
       "      <td>zip</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>QUINCY</td>\n",
       "      <td>Moses Lake, WA</td>\n",
       "      <td>Grant County</td>\n",
       "      <td>GRANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17875</td>\n",
       "      <td>100002</td>\n",
       "      <td>22198</td>\n",
       "      <td>98850</td>\n",
       "      <td>zip</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>ROCK ISLAND</td>\n",
       "      <td>Wenatchee, WA</td>\n",
       "      <td>Douglas County</td>\n",
       "      <td>DOUGLAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10719</td>\n",
       "      <td>100003</td>\n",
       "      <td>11596</td>\n",
       "      <td>98851</td>\n",
       "      <td>zip</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>SOAP LAKE</td>\n",
       "      <td>Moses Lake, WA</td>\n",
       "      <td>Grant County</td>\n",
       "      <td>GRANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20101</td>\n",
       "      <td>100004</td>\n",
       "      <td>26355</td>\n",
       "      <td>98852</td>\n",
       "      <td>zip</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>STEHEKIN</td>\n",
       "      <td>Wenatchee, WA</td>\n",
       "      <td>Chelan County</td>\n",
       "      <td>CHELAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index RegionID SizeRank RegionName RegionType StateName State         City  \\\n",
       "0  30959       -1        1       3756        zip        NH    NH      LEBANON   \n",
       "1   8021   100000     8306      98848        zip        WA    WA       QUINCY   \n",
       "2  17875   100002    22198      98850        zip        WA    WA  ROCK ISLAND   \n",
       "3  10719   100003    11596      98851        zip        WA    WA    SOAP LAKE   \n",
       "4  20101   100004    26355      98852        zip        WA    WA     STEHEKIN   \n",
       "\n",
       "            Metro      CountyName   County  \n",
       "0      Lebanon-NH  Grafton County  GRAFTON  \n",
       "1  Moses Lake, WA    Grant County    GRANT  \n",
       "2   Wenatchee, WA  Douglas County  DOUGLAS  \n",
       "3  Moses Lake, WA    Grant County    GRANT  \n",
       "4   Wenatchee, WA   Chelan County   CHELAN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zillow_dom_data_timeseries_df = spark.createDataFrame(\n",
    "    zillow_dom_data_timeseries\n",
    ").cache()\n",
    "zillow_home_values_zip_ref_df = spark.createDataFrame(\n",
    "    zillow_home_values_zip_ref\n",
    ").cache()\n",
    "zillow_dom_data_timeseries_df.orderBy('RegionID').dshow()\n",
    "zillow_home_values_zip_ref_df.orderBy('RegionID').dshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472c1a8-bc6b-4f5d-866e-8a46758f90f9",
   "metadata": {},
   "source": [
    "## Zillow Step 3. Ensure MSA as Zipcode\n",
    "\n",
    "Crosswalk and add Zipcodes to MSA Info. Ensure no duplicates and fuzzy search based on City Name and Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3de347c7-7beb-4792-8cb5-55dcd19b6958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>2024-10-05</th>\n",
       "      <th>City</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>County</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>GeoID</th>\n",
       "      <th>CountyFIPS</th>\n",
       "      <th>S2Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>394298</td>\n",
       "      <td>473</td>\n",
       "      <td>Aberdeen, WA</td>\n",
       "      <td>msa</td>\n",
       "      <td>WA</td>\n",
       "      <td>51.0</td>\n",
       "      <td>ABERDEEN</td>\n",
       "      <td>99170</td>\n",
       "      <td>PIERCE</td>\n",
       "      <td>47.678393</td>\n",
       "      <td>-117.371865</td>\n",
       "      <td>5306390056</td>\n",
       "      <td>53063</td>\n",
       "      <td>06097338212157320367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394299</td>\n",
       "      <td>251</td>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>60.0</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>76311</td>\n",
       "      <td>TAYLOR</td>\n",
       "      <td>33.920340</td>\n",
       "      <td>-98.546437</td>\n",
       "      <td>4848594215</td>\n",
       "      <td>48485</td>\n",
       "      <td>09679116401234704717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394304</td>\n",
       "      <td>83</td>\n",
       "      <td>Akron, OH</td>\n",
       "      <td>msa</td>\n",
       "      <td>OH</td>\n",
       "      <td>24.0</td>\n",
       "      <td>AKRON</td>\n",
       "      <td>45362</td>\n",
       "      <td>SUMMIT</td>\n",
       "      <td>40.116590</td>\n",
       "      <td>-84.612424</td>\n",
       "      <td>3903701294</td>\n",
       "      <td>39037</td>\n",
       "      <td>09817824436034892991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394306</td>\n",
       "      <td>295</td>\n",
       "      <td>Albany, GA</td>\n",
       "      <td>msa</td>\n",
       "      <td>GA</td>\n",
       "      <td>65.0</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>31707</td>\n",
       "      <td>DOUGHERTY</td>\n",
       "      <td>31.564073</td>\n",
       "      <td>-84.163457</td>\n",
       "      <td>1309593312</td>\n",
       "      <td>13095</td>\n",
       "      <td>09868083232745789563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394307</td>\n",
       "      <td>330</td>\n",
       "      <td>Albany, OR</td>\n",
       "      <td>msa</td>\n",
       "      <td>OR</td>\n",
       "      <td>39.0</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>97350</td>\n",
       "      <td>CLATSOP</td>\n",
       "      <td>44.555663</td>\n",
       "      <td>-122.930637</td>\n",
       "      <td>4104391904</td>\n",
       "      <td>41043</td>\n",
       "      <td>06107003858569160703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RegionID SizeRank    RegionName RegionType StateName 2024-10-05      City  \\\n",
       "0   394298      473  Aberdeen, WA        msa        WA       51.0  ABERDEEN   \n",
       "1   394299      251   Abilene, TX        msa        TX       60.0   ABILENE   \n",
       "2   394304       83     Akron, OH        msa        OH       24.0     AKRON   \n",
       "3   394306      295    Albany, GA        msa        GA       65.0    ALBANY   \n",
       "4   394307      330    Albany, OR        msa        OR       39.0    ALBANY   \n",
       "\n",
       "   ZipCode     County   Latitude   Longitude       GeoID CountyFIPS  \\\n",
       "0    99170     PIERCE  47.678393 -117.371865  5306390056      53063   \n",
       "1    76311     TAYLOR  33.920340  -98.546437  4848594215      48485   \n",
       "2    45362     SUMMIT  40.116590  -84.612424  3903701294      39037   \n",
       "3    31707  DOUGHERTY  31.564073  -84.163457  1309593312      13095   \n",
       "4    97350    CLATSOP  44.555663 -122.930637  4104391904      41043   \n",
       "\n",
       "                   S2Id  \n",
       "0  06097338212157320367  \n",
       "1  09679116401234704717  \n",
       "2  09817824436034892991  \n",
       "3  09868083232745789563  \n",
       "4  06107003858569160703  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fuzzy join on City name and Deduplicate/Group; Collect Mode of County and Zipcode\n",
    "data_cols = \", \".join([f\"\"\"`{col}`\"\"\" for col in zillow_dom_data_timeseries_df.columns])\n",
    "zillow_zip_referenced = spark.sql(\n",
    "    f\"\"\"select z.*, Latitude, Longitude, substr(lpad(GeoID, 10, \"0\"), 0, 10) GeoID, CountyFIPS, c.S2Id from\n",
    "        (select {data_cols}, cast(mode(ZipCode) as int) ZipCode, mode(County) County from \n",
    "            (select a.*, b.ZipCode, b.County from {zillow_dom_data_timeseries_df.reg()} a\n",
    "                left join \n",
    "                    (select *, substr(lpad(RegionName, 5, \"0\"), 0, 5) as ZipCode from {zillow_home_values_zip_ref_df.reg()}) b\n",
    "                    on \n",
    "                    (a.City=b.City or instr(a.City, b.City) >=1 or instr(b.City, a.City) >=1) and \n",
    "                    a.StateName=b.StateName and b.RegionName is not null) x\n",
    "        group by {data_cols}) z\n",
    "    left join {geocodes_df.reg()} c on z.ZipCode=c.ZIP\"\"\"\n",
    ")\n",
    "zillow_zip_referenced.orderBy(\"RegionID\").dshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025241e9-0891-4a9c-b98b-feb8a52a2f51",
   "metadata": {},
   "source": [
    "## Zillow Step 4. Check all MSAs are Mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa957f3-d8f2-4cc6-931d-9e1044409ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(zillow_zip_referenced.filter(\"ZipCode is null\").count() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a2f0de-d67e-48b9-a284-d5532708b158",
   "metadata": {},
   "source": [
    "# Download Social Vulnerability Index Data from CDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d801d2f-b471-4531-998a-548369d6510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pyspark/sql/pandas/conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n",
      "24/11/08 09:43:21 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/11/08 09:43:21 WARN TaskSetManager: Stage 34 contains a task of very large size (4670 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ST_ABBR</th>\n",
       "      <th>STCNTY</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>AREA_SQMI</th>\n",
       "      <th>E_TOTPOP</th>\n",
       "      <th>E_HU</th>\n",
       "      <th>...</th>\n",
       "      <th>E_NHPI</th>\n",
       "      <th>E_TWOMORE</th>\n",
       "      <th>E_OTHERRACE</th>\n",
       "      <th>rowId</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>GeoID</th>\n",
       "      <th>CountyFIPS</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>S2Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>01003010708</td>\n",
       "      <td>Census Tract 107.08; Baldwin County; Alabama</td>\n",
       "      <td>31.471145448452</td>\n",
       "      <td>11526</td>\n",
       "      <td>4313</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>49</td>\n",
       "      <td>26</td>\n",
       "      <td>30.521592</td>\n",
       "      <td>-87.749136</td>\n",
       "      <td>0100390846</td>\n",
       "      <td>01003</td>\n",
       "      <td>36526</td>\n",
       "      <td>09843299529118305827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>01003010711</td>\n",
       "      <td>Census Tract 107.11; Baldwin County; Alabama</td>\n",
       "      <td>1.370962487356</td>\n",
       "      <td>3890</td>\n",
       "      <td>1925</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>30.521592</td>\n",
       "      <td>-87.749136</td>\n",
       "      <td>0100390846</td>\n",
       "      <td>01003</td>\n",
       "      <td>36526</td>\n",
       "      <td>09843299529118305827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>01073</td>\n",
       "      <td>Jefferson County</td>\n",
       "      <td>01073000500</td>\n",
       "      <td>Census Tract 5; Jefferson County; Alabama</td>\n",
       "      <td>1.807211029014</td>\n",
       "      <td>2995</td>\n",
       "      <td>1540</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>33.517576</td>\n",
       "      <td>-86.817855</td>\n",
       "      <td>0107392385</td>\n",
       "      <td>01073</td>\n",
       "      <td>35444</td>\n",
       "      <td>09838425136801829203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>01097</td>\n",
       "      <td>Mobile County</td>\n",
       "      <td>01097003100</td>\n",
       "      <td>Census Tract 31; Mobile County; Alabama</td>\n",
       "      <td>2.380561302056</td>\n",
       "      <td>4711</td>\n",
       "      <td>1973</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>964</td>\n",
       "      <td>30.681075</td>\n",
       "      <td>-88.156308</td>\n",
       "      <td>0109792187</td>\n",
       "      <td>01097</td>\n",
       "      <td>36689</td>\n",
       "      <td>09843264900684253535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "      <td>04005</td>\n",
       "      <td>Coconino County</td>\n",
       "      <td>04005000700</td>\n",
       "      <td>Census Tract 7; Coconino County; Arizona</td>\n",
       "      <td>2.3890833454</td>\n",
       "      <td>4667</td>\n",
       "      <td>1893</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>345</td>\n",
       "      <td>8</td>\n",
       "      <td>1677</td>\n",
       "      <td>35.515056</td>\n",
       "      <td>-111.637340</td>\n",
       "      <td>0400591198</td>\n",
       "      <td>04005</td>\n",
       "      <td>85931</td>\n",
       "      <td>09741971041521842387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ST    STATE ST_ABBR STCNTY            COUNTY         FIPS  \\\n",
       "0  01  Alabama      AL  01003    Baldwin County  01003010708   \n",
       "1  01  Alabama      AL  01003    Baldwin County  01003010711   \n",
       "2  01  Alabama      AL  01073  Jefferson County  01073000500   \n",
       "3  01  Alabama      AL  01097     Mobile County  01097003100   \n",
       "4  04  Arizona      AZ  04005   Coconino County  04005000700   \n",
       "\n",
       "                                       LOCATION        AREA_SQMI E_TOTPOP  \\\n",
       "0  Census Tract 107.08; Baldwin County; Alabama  31.471145448452    11526   \n",
       "1  Census Tract 107.11; Baldwin County; Alabama   1.370962487356     3890   \n",
       "2     Census Tract 5; Jefferson County; Alabama   1.807211029014     2995   \n",
       "3       Census Tract 31; Mobile County; Alabama   2.380561302056     4711   \n",
       "4      Census Tract 7; Coconino County; Arizona     2.3890833454     4667   \n",
       "\n",
       "   E_HU  ... E_NHPI E_TWOMORE E_OTHERRACE rowId   Latitude   Longitude  \\\n",
       "0  4313  ...      0       477          49    26  30.521592  -87.749136   \n",
       "1  1925  ...      0       182           0    29  30.521592  -87.749136   \n",
       "2  1540  ...      0         0           0   474  33.517576  -86.817855   \n",
       "3  1973  ...      0       338           0   964  30.681075  -88.156308   \n",
       "4  1893  ...     86       345           8  1677  35.515056 -111.637340   \n",
       "\n",
       "        GeoID CountyFIPS    ZIP                  S2Id  \n",
       "0  0100390846      01003  36526  09843299529118305827  \n",
       "1  0100390846      01003  36526  09843299529118305827  \n",
       "2  0107392385      01073  35444  09838425136801829203  \n",
       "3  0109792187      01097  36689  09843264900684253535  \n",
       "4  0400591198      04005  85931  09741971041521842387  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "svi_data_file = \"data/svi_data_2022.csv\"\n",
    "svi_data_file_exists = os.path.exists(svi_data_file)  # Does the SVI file aready exist?\n",
    "\n",
    "# Read from Internet if mapping from Metro to Geo data is NOT already present\n",
    "svi_data = (\n",
    "    pd.read_csv(\n",
    "        \"https://svi.cdc.gov/Documents/Data/2022/csv/states/SVI_2022_US.csv\",\n",
    "        dtype=str,\n",
    "    )\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    if not svi_data_file_exists\n",
    "    else pd.read_csv(svi_data_file, dtype=str).fillna(\"\").astype(str)\n",
    ")\n",
    "\n",
    "svi_data = svi_data[\n",
    "    [\n",
    "        col\n",
    "        for col in svi_data.columns\n",
    "        if col[:3] not in (\"MP_\", \"EP_\") and col[:2] not in (\"M_\")\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Comprehensive rename dictionary based on the SVI documentation and image categories\n",
    "rename_dict = {\n",
    "    # Basic Information\n",
    "    \"LOCATION\": \"Location Description\",\n",
    "    \"AREA_SQMI\": \"Area in Square Miles\",\n",
    "    # Population and Housing Estimates\n",
    "    \"E_TOTPOP\": \"Estimated Total Population\",\n",
    "    \"M_TOTPOP\": \"Margin of Error for Total Population\",\n",
    "    \"E_HU\": \"Estimated Housing Units\",\n",
    "    \"M_HU\": \"Margin of Error for Housing Units\",\n",
    "    \"E_HH\": \"Estimated Households\",\n",
    "    \"M_HH\": \"Margin of Error for Households\",\n",
    "    # Socioeconomic Status (Theme 1)\n",
    "    \"EP_POV150\": \"Percentage Below 150% Poverty\",\n",
    "    \"MP_POV150\": \"Margin of Error for Percentage Below 150% Poverty\",\n",
    "    \"EP_UNEMP\": \"Unemployment Rate\",\n",
    "    \"MP_UNEMP\": \"Margin of Error for Unemployment Rate\",\n",
    "    \"EP_HBURD\": \"Percentage with Housing Cost Burden\",\n",
    "    \"MP_HBURD\": \"Margin of Error for Housing Cost Burden\",\n",
    "    \"EP_NOHSDP\": \"Percentage with No High School Diploma\",\n",
    "    \"MP_NOHSDP\": \"Margin of Error for No High School Diploma\",\n",
    "    \"EP_UNINSUR\": \"Percentage Uninsured\",\n",
    "    \"MP_UNINSUR\": \"Margin of Error for Uninsured\",\n",
    "    # Household Characteristics (Theme 2)\n",
    "    \"EP_AGE65\": \"Percentage Aged 65 & Older\",\n",
    "    \"MP_AGE65\": \"Margin of Error for Aged 65 & Older\",\n",
    "    \"EP_AGE17\": \"Percentage Aged 17 & Younger\",\n",
    "    \"MP_AGE17\": \"Margin of Error for Aged 17 & Younger\",\n",
    "    \"EP_DISABL\": \"Percentage with a Disability\",\n",
    "    \"MP_DISABL\": \"Margin of Error for Disability\",\n",
    "    \"EP_SNGPNT\": \"Percentage Single-Parent Households\",\n",
    "    \"MP_SNGPNT\": \"Margin of Error for Single-Parent Households\",\n",
    "    \"EP_LIMENG\": \"Percentage with Limited English Proficiency\",\n",
    "    \"MP_LIMENG\": \"Margin of Error for Limited English Proficiency\",\n",
    "    # Racial & Ethnic Minority Status (Theme 3)\n",
    "    \"EP_MINRTY\": \"Percentage Minority\",\n",
    "    \"MP_MINRTY\": \"Margin of Error for Minority Status\",\n",
    "    \"EP_HISP\": \"Percentage Hispanic or Latino\",\n",
    "    \"MP_HISP\": \"Margin of Error for Hispanic or Latino\",\n",
    "    \"EP_AFAM\": \"Percentage Black or African American, Not Hispanic\",\n",
    "    \"MP_AFAM\": \"Margin of Error for Black or African American, Not Hispanic\",\n",
    "    \"EP_ASIAN\": \"Percentage Asian, Not Hispanic\",\n",
    "    \"MP_ASIAN\": \"Margin of Error for Asian, Not Hispanic\",\n",
    "    \"EP_AIAN\": \"Percentage American Indian/Alaska Native, Not Hispanic\",\n",
    "    \"MP_AIAN\": \"Margin of Error for American Indian/Alaska Native, Not Hispanic\",\n",
    "    \"EP_NHPI\": \"Percentage Native Hawaiian/Pacific Islander, Not Hispanic\",\n",
    "    \"MP_NHPI\": \"Margin of Error for Native Hawaiian/Pacific Islander, Not Hispanic\",\n",
    "    \"EP_TWOMORE\": \"Percentage Two or More Races, Not Hispanic\",\n",
    "    \"MP_TWOMORE\": \"Margin of Error for Two or More Races, Not Hispanic\",\n",
    "    \"EP_OTHERRACE\": \"Percentage Other Race, Not Hispanic\",\n",
    "    \"MP_OTHERRACE\": \"Margin of Error for Other Race, Not Hispanic\",\n",
    "    # Raw Estimates for Racial & Ethnic Groups\n",
    "    \"E_AFAM\": \"Estimated Count of Black or African American, Not Hispanic\",\n",
    "    \"E_HISP\": \"Estimated Count of Hispanic or Latino (of any race)\",\n",
    "    \"E_ASIAN\": \"Estimated Count of Asian, Not Hispanic\",\n",
    "    \"E_AIAN\": \"Estimated Count of American Indian or Alaska Native, Not Hispanic\",\n",
    "    \"E_NHPI\": \"Estimated Count of Native Hawaiian or Other Pacific Islander, Not Hispanic\",\n",
    "    \"E_TWOMORE\": \"Estimated Count of Two or More Races, Not Hispanic\",\n",
    "    \"E_OTHERRACE\": \"Estimated Count of Other Race, Not Hispanic\",\n",
    "    # Housing Type & Transportation (Theme 4)\n",
    "    \"EP_MUNIT\": \"Percentage in Multi-Unit Structures\",\n",
    "    \"MP_MUNIT\": \"Margin of Error for Multi-Unit Structures\",\n",
    "    \"EP_MOBILE\": \"Percentage Mobile Homes\",\n",
    "    \"MP_MOBILE\": \"Margin of Error for Mobile Homes\",\n",
    "    \"EP_CROWD\": \"Percentage Crowded Housing\",\n",
    "    \"MP_CROWD\": \"Margin of Error for Crowded Housing\",\n",
    "    \"EP_NOVEH\": \"Percentage with No Vehicle\",\n",
    "    \"MP_NOVEH\": \"Margin of Error for No Vehicle\",\n",
    "    \"EP_GROUPQ\": \"Percentage in Group Quarters\",\n",
    "    \"MP_GROUPQ\": \"Margin of Error for Group Quarters\",\n",
    "    # Percentile Rankings for Each Theme\n",
    "    \"RPL_THEME1\": \"Rank for Socioeconomic Status\",\n",
    "    \"RPL_THEME2\": \"Rank for Household Characteristics\",\n",
    "    \"RPL_THEME3\": \"Rank for Racial & Ethnic Minority Status\",\n",
    "    \"RPL_THEME4\": \"Rank for Housing Type & Transportation\",\n",
    "    \"RPL_THEMES\": \"Overall Social Vulnerability Rank\",\n",
    "    # Flag Indicators\n",
    "    \"F_POV150\": \"Flag for Below 150% Poverty\",\n",
    "    \"F_UNEMP\": \"Flag for Unemployment\",\n",
    "    \"F_HBURD\": \"Flag for Housing Cost Burden\",\n",
    "    \"F_NOHSDP\": \"Flag for No High School Diploma\",\n",
    "    \"F_UNINSUR\": \"Flag for Uninsured\",\n",
    "    \"F_THEME1\": \"Sum of Flags for Socioeconomic Status\",\n",
    "    \"F_AGE65\": \"Flag for Aged 65 & Older\",\n",
    "    \"F_AGE17\": \"Flag for Aged 17 & Younger\",\n",
    "    \"F_DISABL\": \"Flag for Disability\",\n",
    "    \"F_SNGPNT\": \"Flag for Single-Parent Households\",\n",
    "    \"F_LIMENG\": \"Flag for Limited English\",\n",
    "    \"F_THEME2\": \"Sum of Flags for Household Characteristics\",\n",
    "    \"F_MINRTY\": \"Flag for Minority Status\",\n",
    "    \"F_THEME3\": \"Sum of Flags for Racial & Ethnic Minority Status\",\n",
    "    \"F_MUNIT\": \"Flag for Multi-Unit Housing\",\n",
    "    \"F_MOBILE\": \"Flag for Mobile Homes\",\n",
    "    \"F_CROWD\": \"Flag for Crowding\",\n",
    "    \"F_NOVEH\": \"Flag for No Vehicle\",\n",
    "    \"F_GROUPQ\": \"Flag for Group Quarters\",\n",
    "    \"F_THEME4\": \"Sum of Flags for Housing Type & Transportation\",\n",
    "    \"F_TOTAL\": \"Sum of All Flags\",\n",
    "    # Adjunct Variables (for context)\n",
    "    \"E_DAYPOP\": \"Estimated Daytime Population\",\n",
    "    \"E_NOINT\": \"Households without Internet\",\n",
    "    \"M_NOINT\": \"Margin of Error for Households without Internet\",\n",
    "}\n",
    "\n",
    "# Apply the renaming to the DataFrame\n",
    "# svi_data.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "if not svi_data_file_exists:\n",
    "    svi_data.to_csv(\n",
    "        svi_data_file,\n",
    "        index=False,\n",
    "    )  # Save for later\n",
    "    svi_data_file_exists = os.path.exists(svi_data_file)\n",
    "\n",
    "# Stamp the DataFrame with Latitude, Longitude and S2Id from the geocodes DataFrame\n",
    "svi_data_df = (\n",
    "    spark.sql(\n",
    "        f\"\"\"select a.*, c.Latitude, c.Longitude, substr(lpad(GeoID, 10, \"0\"), 0, 10) GeoID, CountyFIPS, ZIP, S2Id\n",
    "    from {spark.createDataFrame(svi_data).withColumn('rowId', F.monotonically_increasing_id()).reg()} a\n",
    "    left join {geocodes_df.reg()} c\n",
    "    on substr(lpad(a.FIPS, 10, \"0\"), 0, 10)=substr(lpad(c.GeoID, 10, \"0\"), 0, 10) or (a.STCNTY=c.CountyFIPS and a.ST_ABBR=c.State)\"\"\"\n",
    "    )\n",
    "    .drop_duplicates([\"rowId\"])\n",
    "    .cache()\n",
    ")\n",
    "svi_data_df.dshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac9134",
   "metadata": {},
   "source": [
    "# Exporting Geomapped CDC and Zillow Data\n",
    "\n",
    "This section of the code is responsible for exporting and persisting crosswalked files as CSVs.\n",
    "Saving these files is crucial for future analysis as it allows us to maintain a record of the data transformations and mappings that have been applied. This ensures that we can trace back the steps taken during data processing, verify the accuracy of our transformations, and reproduce results if needed. Additionally, having these files saved facilitates further analysis and reporting, enabling us to build upon the existing data without reprocessing from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab2f203-ec9f-4ea4-893f-5afd43c5afd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "svi_data_df.toPandas().to_csv(\n",
    "    \"vulnerability_index.csv\", index=False\n",
    ")\n",
    "zillow_zip_referenced.withColumnRenamed(latest_date, \"DOM\").toPandas().to_csv(\n",
    "    \"zillow_dom.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca35030-7fb1-4892-a9ff-1f53359ad3fa",
   "metadata": {},
   "source": [
    "# Normalization and Scaling\n",
    "\n",
    "Normalizing and standardizing the vulnerability indices correctly is essential for meaningful comparisons, especially when dealing with diverse regions with varying population sizes, geographic areas, and socioeconomic conditions. Hereâ€™s how to approach this:\n",
    "\n",
    "### Step 1: Normalize Indices\n",
    "First, adjust indices to make them population- or area-weighted as appropriate. This ensures that metrics like income, racial mix, or housing types account for regional population density or area. Common approaches include:\n",
    "   - **Population-normalized values**: Convert counts to percentages (e.g., percentage of population below the poverty line).\n",
    "   - **Area-normalized values**: Calculate values per unit area if certain indices depend on geography (e.g., housing density).\n",
    "\n",
    "### Step 2: Standardize to Z-Scores (Unit Normal Scale)\n",
    "Standardizing the indices helps you compare across metros with inherently different scales. This can be achieved using **z-scores**, which center the values around a mean of 0 and standard deviation of 1.\n",
    "\n",
    "### Step 3: Standardize Zillow Metrics\n",
    "Since Zillow metrics like home prices may vary widely across metros, it could also be beneficial to standardize these values. This ensures that analyses are focused on relative trends rather than absolute values.\n",
    "\n",
    "### Step 4: Merge and Analyze\n",
    "With standardized values, you can now merge the Zillow and SVI data, making meaningful comparisons between indices and housing metrics across regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dff01839-c73e-4bee-b54f-f8533113d1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>DOM</th>\n",
       "      <th>City</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>County</th>\n",
       "      <th>Latitude_zillow</th>\n",
       "      <th>...</th>\n",
       "      <th>DENSITY_AGE17</th>\n",
       "      <th>DENSITY_DISABL</th>\n",
       "      <th>DENSITY_SNGPNT</th>\n",
       "      <th>DENSITY_LIMENG</th>\n",
       "      <th>DENSITY_MINRTY</th>\n",
       "      <th>DENSITY_MUNIT</th>\n",
       "      <th>DENSITY_MOBILE</th>\n",
       "      <th>DENSITY_CROWD</th>\n",
       "      <th>DENSITY_NOVEH</th>\n",
       "      <th>DENSITY_GROUPQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>394359</td>\n",
       "      <td>288</td>\n",
       "      <td>Bangor, ME</td>\n",
       "      <td>msa</td>\n",
       "      <td>ME</td>\n",
       "      <td>41.0</td>\n",
       "      <td>BANGOR</td>\n",
       "      <td>4402</td>\n",
       "      <td>PENOBSCOT</td>\n",
       "      <td>44.99074795000001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081803</td>\n",
       "      <td>-0.075641</td>\n",
       "      <td>-0.092566</td>\n",
       "      <td>-0.163310</td>\n",
       "      <td>-0.087080</td>\n",
       "      <td>-0.064732</td>\n",
       "      <td>-0.089347</td>\n",
       "      <td>-0.070081</td>\n",
       "      <td>-0.029047</td>\n",
       "      <td>-0.251746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394788</td>\n",
       "      <td>367</td>\n",
       "      <td>Lewiston, ME</td>\n",
       "      <td>msa</td>\n",
       "      <td>ME</td>\n",
       "      <td>18.0</td>\n",
       "      <td>LEWISTON</td>\n",
       "      <td>4050</td>\n",
       "      <td>ANDROSCOGGIN</td>\n",
       "      <td>43.751804898765435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090074</td>\n",
       "      <td>-0.096018</td>\n",
       "      <td>-0.092566</td>\n",
       "      <td>-0.178616</td>\n",
       "      <td>-0.086562</td>\n",
       "      <td>-0.073884</td>\n",
       "      <td>-0.101208</td>\n",
       "      <td>-0.082287</td>\n",
       "      <td>-0.075013</td>\n",
       "      <td>-0.172835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394997</td>\n",
       "      <td>105</td>\n",
       "      <td>Portland, ME</td>\n",
       "      <td>msa</td>\n",
       "      <td>ME</td>\n",
       "      <td>29.0</td>\n",
       "      <td>PORTLAND</td>\n",
       "      <td>4101</td>\n",
       "      <td>CUMBERLAND</td>\n",
       "      <td>43.751804898765435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090074</td>\n",
       "      <td>-0.096018</td>\n",
       "      <td>-0.092566</td>\n",
       "      <td>-0.178616</td>\n",
       "      <td>-0.086562</td>\n",
       "      <td>-0.073884</td>\n",
       "      <td>-0.101208</td>\n",
       "      <td>-0.082287</td>\n",
       "      <td>-0.075013</td>\n",
       "      <td>-0.172835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394353</td>\n",
       "      <td>339</td>\n",
       "      <td>Augusta, ME</td>\n",
       "      <td>msa</td>\n",
       "      <td>ME</td>\n",
       "      <td>36.0</td>\n",
       "      <td>AUGUSTA</td>\n",
       "      <td>4050</td>\n",
       "      <td>KENNEBEC</td>\n",
       "      <td>43.751804898765435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090074</td>\n",
       "      <td>-0.096018</td>\n",
       "      <td>-0.092566</td>\n",
       "      <td>-0.178616</td>\n",
       "      <td>-0.086562</td>\n",
       "      <td>-0.073884</td>\n",
       "      <td>-0.101208</td>\n",
       "      <td>-0.082287</td>\n",
       "      <td>-0.075013</td>\n",
       "      <td>-0.172835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394759</td>\n",
       "      <td>519</td>\n",
       "      <td>Laconia, NH</td>\n",
       "      <td>msa</td>\n",
       "      <td>NH</td>\n",
       "      <td>39.0</td>\n",
       "      <td>LACONIA</td>\n",
       "      <td>3246</td>\n",
       "      <td>BELKNAP</td>\n",
       "      <td>43.52958755555556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072527</td>\n",
       "      <td>-0.083714</td>\n",
       "      <td>-0.066159</td>\n",
       "      <td>-0.179198</td>\n",
       "      <td>-0.084591</td>\n",
       "      <td>-0.073884</td>\n",
       "      <td>-0.095713</td>\n",
       "      <td>-0.091870</td>\n",
       "      <td>-0.077453</td>\n",
       "      <td>-0.264472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>394719</td>\n",
       "      <td>328</td>\n",
       "      <td>Jamestown, NY</td>\n",
       "      <td>msa</td>\n",
       "      <td>NY</td>\n",
       "      <td>38.0</td>\n",
       "      <td>JAMESTOWN</td>\n",
       "      <td>11770</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>40.82983666857143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095663</td>\n",
       "      <td>-0.103980</td>\n",
       "      <td>-0.092464</td>\n",
       "      <td>-0.177978</td>\n",
       "      <td>-0.089131</td>\n",
       "      <td>-0.073884</td>\n",
       "      <td>-0.101361</td>\n",
       "      <td>-0.091050</td>\n",
       "      <td>-0.080189</td>\n",
       "      <td>-0.264161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>845159</td>\n",
       "      <td>86</td>\n",
       "      <td>Poughkeepsie, NY</td>\n",
       "      <td>msa</td>\n",
       "      <td>NY</td>\n",
       "      <td>57.0</td>\n",
       "      <td>POUGHKEEPSIE</td>\n",
       "      <td>11770</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>40.82983666857143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095663</td>\n",
       "      <td>-0.103980</td>\n",
       "      <td>-0.092464</td>\n",
       "      <td>-0.177978</td>\n",
       "      <td>-0.089131</td>\n",
       "      <td>-0.073884</td>\n",
       "      <td>-0.101361</td>\n",
       "      <td>-0.091050</td>\n",
       "      <td>-0.080189</td>\n",
       "      <td>-0.264161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>394633</td>\n",
       "      <td>331</td>\n",
       "      <td>Glens Falls, NY</td>\n",
       "      <td>msa</td>\n",
       "      <td>NY</td>\n",
       "      <td>33.0</td>\n",
       "      <td>GLENS FALLS</td>\n",
       "      <td>11770</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>40.82983666857143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095663</td>\n",
       "      <td>-0.103980</td>\n",
       "      <td>-0.092464</td>\n",
       "      <td>-0.177978</td>\n",
       "      <td>-0.089131</td>\n",
       "      <td>-0.073884</td>\n",
       "      <td>-0.101361</td>\n",
       "      <td>-0.091050</td>\n",
       "      <td>-0.080189</td>\n",
       "      <td>-0.264161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>394387</td>\n",
       "      <td>195</td>\n",
       "      <td>Binghamton, NY</td>\n",
       "      <td>msa</td>\n",
       "      <td>NY</td>\n",
       "      <td>34.0</td>\n",
       "      <td>BINGHAMTON</td>\n",
       "      <td>11770</td>\n",
       "      <td>BROOME</td>\n",
       "      <td>40.82983666857143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095663</td>\n",
       "      <td>-0.103980</td>\n",
       "      <td>-0.092464</td>\n",
       "      <td>-0.177978</td>\n",
       "      <td>-0.089131</td>\n",
       "      <td>-0.073884</td>\n",
       "      <td>-0.101361</td>\n",
       "      <td>-0.091050</td>\n",
       "      <td>-0.080189</td>\n",
       "      <td>-0.264161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>394308</td>\n",
       "      <td>64</td>\n",
       "      <td>Albany, NY</td>\n",
       "      <td>msa</td>\n",
       "      <td>NY</td>\n",
       "      <td>27.0</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>11770</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>40.82983666857143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095663</td>\n",
       "      <td>-0.103980</td>\n",
       "      <td>-0.092464</td>\n",
       "      <td>-0.177978</td>\n",
       "      <td>-0.089131</td>\n",
       "      <td>-0.073884</td>\n",
       "      <td>-0.101361</td>\n",
       "      <td>-0.091050</td>\n",
       "      <td>-0.080189</td>\n",
       "      <td>-0.264161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RegionID SizeRank        RegionName RegionType StateName   DOM  \\\n",
       "0     394359      288        Bangor, ME        msa        ME  41.0   \n",
       "1     394788      367      Lewiston, ME        msa        ME  18.0   \n",
       "2     394997      105      Portland, ME        msa        ME  29.0   \n",
       "3     394353      339       Augusta, ME        msa        ME  36.0   \n",
       "4     394759      519       Laconia, NH        msa        NH  39.0   \n",
       "..       ...      ...               ...        ...       ...   ...   \n",
       "327   394719      328     Jamestown, NY        msa        NY  38.0   \n",
       "328   845159       86  Poughkeepsie, NY        msa        NY  57.0   \n",
       "329   394633      331   Glens Falls, NY        msa        NY  33.0   \n",
       "330   394387      195    Binghamton, NY        msa        NY  34.0   \n",
       "331   394308       64        Albany, NY        msa        NY  27.0   \n",
       "\n",
       "             City ZipCode        County     Latitude_zillow  ...  \\\n",
       "0          BANGOR    4402     PENOBSCOT   44.99074795000001  ...   \n",
       "1        LEWISTON    4050  ANDROSCOGGIN  43.751804898765435  ...   \n",
       "2        PORTLAND    4101    CUMBERLAND  43.751804898765435  ...   \n",
       "3         AUGUSTA    4050      KENNEBEC  43.751804898765435  ...   \n",
       "4         LACONIA    3246       BELKNAP   43.52958755555556  ...   \n",
       "..            ...     ...           ...                 ...  ...   \n",
       "327     JAMESTOWN   11770     JEFFERSON   40.82983666857143  ...   \n",
       "328  POUGHKEEPSIE   11770     JEFFERSON   40.82983666857143  ...   \n",
       "329   GLENS FALLS   11770     JEFFERSON   40.82983666857143  ...   \n",
       "330    BINGHAMTON   11770        BROOME   40.82983666857143  ...   \n",
       "331        ALBANY   11770        ALBANY   40.82983666857143  ...   \n",
       "\n",
       "    DENSITY_AGE17 DENSITY_DISABL DENSITY_SNGPNT  DENSITY_LIMENG  \\\n",
       "0       -0.081803      -0.075641      -0.092566       -0.163310   \n",
       "1       -0.090074      -0.096018      -0.092566       -0.178616   \n",
       "2       -0.090074      -0.096018      -0.092566       -0.178616   \n",
       "3       -0.090074      -0.096018      -0.092566       -0.178616   \n",
       "4       -0.072527      -0.083714      -0.066159       -0.179198   \n",
       "..            ...            ...            ...             ...   \n",
       "327     -0.095663      -0.103980      -0.092464       -0.177978   \n",
       "328     -0.095663      -0.103980      -0.092464       -0.177978   \n",
       "329     -0.095663      -0.103980      -0.092464       -0.177978   \n",
       "330     -0.095663      -0.103980      -0.092464       -0.177978   \n",
       "331     -0.095663      -0.103980      -0.092464       -0.177978   \n",
       "\n",
       "     DENSITY_MINRTY DENSITY_MUNIT DENSITY_MOBILE DENSITY_CROWD DENSITY_NOVEH  \\\n",
       "0         -0.087080     -0.064732      -0.089347     -0.070081     -0.029047   \n",
       "1         -0.086562     -0.073884      -0.101208     -0.082287     -0.075013   \n",
       "2         -0.086562     -0.073884      -0.101208     -0.082287     -0.075013   \n",
       "3         -0.086562     -0.073884      -0.101208     -0.082287     -0.075013   \n",
       "4         -0.084591     -0.073884      -0.095713     -0.091870     -0.077453   \n",
       "..              ...           ...            ...           ...           ...   \n",
       "327       -0.089131     -0.073884      -0.101361     -0.091050     -0.080189   \n",
       "328       -0.089131     -0.073884      -0.101361     -0.091050     -0.080189   \n",
       "329       -0.089131     -0.073884      -0.101361     -0.091050     -0.080189   \n",
       "330       -0.089131     -0.073884      -0.101361     -0.091050     -0.080189   \n",
       "331       -0.089131     -0.073884      -0.101361     -0.091050     -0.080189   \n",
       "\n",
       "    DENSITY_GROUPQ  \n",
       "0        -0.251746  \n",
       "1        -0.172835  \n",
       "2        -0.172835  \n",
       "3        -0.172835  \n",
       "4        -0.264472  \n",
       "..             ...  \n",
       "327      -0.264161  \n",
       "328      -0.264161  \n",
       "329      -0.264161  \n",
       "330      -0.264161  \n",
       "331      -0.264161  \n",
       "\n",
       "[332 rows x 120 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load Zillow and SVI data as strings to prevent unwanted type conversions\n",
    "zillow_data = pd.read_csv(\"zillow_dom.csv\", dtype=str)\n",
    "svi_data = pd.read_csv(\"vulnerability_index.csv\", dtype=str)\n",
    "\n",
    "# Drop rows from SVI data where population is zero (likely unusable data points)\n",
    "svi_data = svi_data.loc[svi_data[\"E_TOTPOP\"] != 0]\n",
    "\n",
    "# Drop rows from Zillow data where 'DOM' (Days on Market) is null\n",
    "zillow_data = zillow_data.loc[~zillow_data[\"DOM\"].isna()]\n",
    "\n",
    "# Convert 'DOM' column to float for further numeric operations\n",
    "zillow_data['DENSITY_DOM'] = zillow_data['DOM'].astype(float)\n",
    "\n",
    "# Define key columns for normalization calculations\n",
    "population_col = \"E_TOTPOP\"       # Total population\n",
    "area_col = \"AREA_SQMI\"            # Area in square miles\n",
    "housing_units_col = \"E_HU\"        # Housing units count\n",
    "\n",
    "# Calculate population density as people per square mile and add to SVI data\n",
    "svi_data[\"POP_DENSITY\"] = svi_data[population_col].astype(float) / svi_data[area_col].astype(float)\n",
    "\n",
    "# Normalize key SVI metrics by population density to get density-based attributes\n",
    "# Each calculation creates a new column in SVI data, e.g., 'DENSITY_POV150' for poverty density\n",
    "svi_data[\"DENSITY_POV150\"] = svi_data[\"E_POV150\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_UNEMP\"] = svi_data[\"E_UNEMP\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_NOHSDP\"] = svi_data[\"E_NOHSDP\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_UNINSUR\"] = svi_data[\"E_UNINSUR\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_AGE65\"] = svi_data[\"E_AGE65\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_AGE17\"] = svi_data[\"E_AGE17\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_DISABL\"] = svi_data[\"E_DISABL\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_SNGPNT\"] = svi_data[\"E_SNGPNT\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_LIMENG\"] = svi_data[\"E_LIMENG\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_MINRTY\"] = svi_data[\"E_MINRTY\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_MUNIT\"] = svi_data[\"E_MUNIT\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_MOBILE\"] = svi_data[\"E_MOBILE\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_CROWD\"] = svi_data[\"E_CROWD\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_NOVEH\"] = svi_data[\"E_NOVEH\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "svi_data[\"DENSITY_GROUPQ\"] = svi_data[\"E_GROUPQ\"].astype(float) / svi_data[\"POP_DENSITY\"]\n",
    "\n",
    "# List of SVI columns to be standardized later in the code\n",
    "svi_columns_to_standardize = [\n",
    "    \"DENSITY_POV150\", \"DENSITY_UNEMP\", \"DENSITY_NOHSDP\", \"DENSITY_UNINSUR\", \n",
    "    \"DENSITY_AGE65\", \"DENSITY_AGE17\", \"DENSITY_DISABL\", \"DENSITY_SNGPNT\", \n",
    "    \"DENSITY_LIMENG\", \"DENSITY_MINRTY\", \"DENSITY_MUNIT\", \"DENSITY_MOBILE\", \n",
    "    \"DENSITY_CROWD\", \"DENSITY_NOVEH\", \"DENSITY_GROUPQ\",\n",
    "]\n",
    "\n",
    "# Zillow columns to standardize, which currently includes only 'DENSITY_DOM'\n",
    "zillow_columns_to_standardize = [\"DENSITY_DOM\"]\n",
    "\n",
    "# Remove rows with null or invalid S2 IDs (spatial ID) from both datasets\n",
    "zillow_data = zillow_data.dropna(subset=[\"S2Id\"]).sort_values(by=\"S2Id\")\n",
    "svi_data = svi_data.dropna(subset=[\"S2Id\"]).sort_values(by=\"S2Id\")\n",
    "\n",
    "# Convert S2Id to integer (assuming S2Id needs truncation and standardization)\n",
    "zillow_data[\"S2Id\"] = zillow_data[\"S2Id\"].apply(lambda x: int(x[:16]) if x else None).astype(int)\n",
    "svi_data[\"S2Id\"] = svi_data[\"S2Id\"].apply(lambda x: int(x[:16]) if x else None).astype(int)\n",
    "\n",
    "# Perform an approximate merge on S2 IDs to match the nearest S2 ID between Zillow and SVI data\n",
    "# This uses a \"nearest\" join on sorted S2 IDs to allow approximate spatial matching\n",
    "merged_data = pd.merge_asof(\n",
    "    zillow_data, svi_data, on=\"S2Id\", direction=\"nearest\", suffixes=(\"_zillow\", \"_svi\")\n",
    ")\n",
    "\n",
    "# Standardize SVI and Zillow columns based on density (z-score normalization)\n",
    "# This ensures each density column has a mean of 0 and standard deviation of 1 for consistent scaling\n",
    "scaler = StandardScaler()\n",
    "merged_data[svi_columns_to_standardize + zillow_columns_to_standardize] = scaler.fit_transform(\n",
    "    merged_data[svi_columns_to_standardize + zillow_columns_to_standardize]\n",
    ")\n",
    "\n",
    "# Display and save the merged data to a CSV file\n",
    "# The standardized data is saved to 'training_ready_data.csv' for further analysis\n",
    "display(merged_data)\n",
    "merged_data.to_csv('training_ready_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a613445",
   "metadata": {},
   "source": [
    "# Analyze\n",
    "\n",
    "Analyze the dataset for any Zillow metrics correlations with CDC vulnerability metrics (normalized/standardized) in a separate notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
